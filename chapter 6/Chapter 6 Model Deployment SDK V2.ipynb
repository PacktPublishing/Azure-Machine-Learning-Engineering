{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Model to online endpoint\n",
    "\n",
    "- Models created with MLFlow do not require a scoring script nor an environment, with this notebook, we will create a scopy.py file and use that with our model.\n",
    "\n",
    "- Before running this notebook, run the **Chapter 6 Prep-Model Creation & Registration.ipynb** notebook to create and register a model for use\n",
    "\n",
    "- Models created with MLFlow do not require a scoring script nor an environment\n",
    "\n",
    "## In this notebook we will:\n",
    "\n",
    "- Connect to your workspace.\n",
    "- Create an online endpoint\n",
    "- Retrieve and register a model from the job ran in the previous notebook\n",
    "- Create a deployment\n",
    "- Make an API Call to the managed online endpoint\n",
    "\n",
    "Let's get started\n",
    "\n",
    "You can use either the Python 3.10 - SDK V2 kernel, or your job_env kenel to run this notebook.\n",
    "\n",
    "**Kernel** > **Change Kernel** > **Python 3.10 - SDK V2**\n",
    "\n",
    "or if you already setup the virtual environment in Chapter 4:\n",
    "\n",
    "Select **Kernel** > **Change Kernel** > **job_env**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.2\n"
     ]
    }
   ],
   "source": [
    "import azure.ai.ml\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "\n",
    "print(azure.ai.ml._version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "resource_group = \"<RESOURCE_GROUP>\"\n",
    "workspace = \"<AML_WORKSPACE_NAME>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "import datetime\n",
    "\n",
    "online_endpoint_name = \"ch6-sdkv2-endpt-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"titanic online endpoint for mlflow model\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"oneline endpoint\": \"titanic\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create endpoint\n",
    "\n",
    "Using the MLClient created earlier, we will now create the Endpoint in the workspace. This command will start the endpoint creation and return a confirmation response while the endpoint creation continues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7fd4ab5d80a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch6-sdkv2-endpt-12102241150428\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Succeeded\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(online_endpoint_name)\n",
    "while ml_client.online_endpoints.get(name=online_endpoint_name).provisioning_state == 'Creating':\n",
    "    print('Creating')\n",
    "    time.sleep(15)\n",
    "\n",
    "print(ml_client.online_endpoints.get(name=online_endpoint_name).provisioning_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create deployment\n",
    "A deployment is a set of resouces used for hosting the inferecing model using the *ManagedOnlineDeployment* class.  \n",
    "Using the *ManagedOnlineDeployment* class, a developer can configure the following components\n",
    "\n",
    "- name: name of the deployment\n",
    "- endpoint_name: name of the endpoint to create the deployment under\n",
    "- model: the model to use for the deployment\n",
    "- instance_type: the VM side to use for deployment\n",
    "- instance_count: the number of instances to use for the deployment\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Model from registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7b6a371b-4dc8-435d-8358-e482be62200e\n",
      "tidy_cassava_0ll0gyn6mv\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_596917/3874377315.py:15: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  file_path = client.download_artifacts(\n"
     ]
    }
   ],
   "source": [
    "experiment = 'chapter6'\n",
    "current_experiment=dict(mlflow.get_experiment_by_name(experiment))\n",
    "experiment_id=current_experiment['experiment_id']\n",
    "print(experiment_id)\n",
    "\n",
    "df = mlflow.search_runs([experiment_id])\n",
    "run_id = df['run_id'].iloc[-1]\n",
    "print(run_id)\n",
    "print(type(run_id))\n",
    "\n",
    "mlflow.set_experiment(experiment_name='chapter6')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "client.list_artifacts(run_id=run_id)\n",
    "\n",
    "file_path = client.download_artifacts(\n",
    "    run_id, path=\"model\"\n",
    ")\n",
    "shutil.copytree(file_path, './model', dirs_exist_ok=True)\n",
    "\n",
    "model = Model(path=\"./model/model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Deployment Environment\n",
    "\n",
    "- MLFlow Models by default create a conda.yaml file which is used with an MLflow base image which contains:\n",
    "    - azureml-inference-server-http\n",
    "    - mlflow-skinny\n",
    "    \n",
    "- In this example, we are downloading the model, so we need to specify the packages we need installed since we are not using the no-code deployment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conda-yamls/env_for_sdkv2deploy.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda-yamls/env_for_sdkv2deploy.yml\n",
    "name: job_env_for_build\n",
    "dependencies:\n",
    "- python=3.10\n",
    "- scikit-learn=1.1.3\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults==1.48.0 #needed for the inferece schema\n",
    "  - mlflow<=1.30.0\n",
    "  - azure-ai-ml==1.1.2\n",
    "  - mltable==1.0.0\n",
    "  - azureml-mlflow==1.48.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment, BuildContext\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "    conda_file=\"conda-yamls/env_for_sdkv2deploy.yml\",\n",
    "    name=\"env_for_sdkv2deploy\",\n",
    "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "env = ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Environment({'is_anonymous': False, 'auto_increment_version': False, 'name': 'env_for_sdkv2deploy', 'description': 'Environment created from a Docker image plus Conda environment.', 'tags': {}, 'properties': {}, 'id': '/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourceGroups/chapter6-azureml-rg/providers/Microsoft.MachineLearningServices/workspaces/chapter6-azureml/environments/env_for_sdkv2deploy/versions/5', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz2/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/chapter 6', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd4888b0610>, 'serialize': <msrest.serialization.Serializer object at 0x7fd4888b0d90>, 'version': '5', 'latest_version': None, 'conda_file': {'dependencies': ['python=3.10', 'scikit-learn=1.1.3', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults==1.48.0', 'mlflow<=1.30.0', 'azure-ai-ml==1.1.2', 'mltable==1.0.0', 'azureml-mlflow==1.48.0']}], 'name': 'job_env_for_build'}, 'image': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04', 'build': None, 'inference_config': None, 'os_type': 'Linux', 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"dependencies\": [\\n    \"python=3.10\",\\n    \"scikit-learn=1.1.3\",\\n    \"ipykernel\",\\n    \"matplotlib\",\\n    \"pandas\",\\n    \"pip\",\\n    {\\n      \"pip\": [\\n        \"azureml-defaults==1.48.0\",\\n        \"mlflow<=1.30.0\",\\n        \"azure-ai-ml==1.1.2\",\\n        \"mltable==1.0.0\",\\n        \"azureml-mlflow==1.48.0\"\\n      ]\\n    }\\n  ],\\n  \"name\": \"job_env_for_build\"\\n}'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Scoring Script\n",
    "\n",
    "score.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ManagedOnlineEndpoint folder created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "script_folder = 'ManagedOnlineEndpoint'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ManagedOnlineEndpoint/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/score.py\n",
    "\n",
    "import os \n",
    "import json\n",
    "import joblib\n",
    "from pandas import json_normalize\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "    logging.info(\"Init complete\")\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    dict= json.loads(raw_data)\n",
    "    df = json_normalize(dict['raw_data']) \n",
    "    y_pred = model.predict(df)\n",
    "    print(type(y_pred))\n",
    "    \n",
    "    result = {\"result\": y_pred.tolist()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"./ManagedOnlineEndpoint\", scoring_script=\"score.py\"\n",
    "    ),\n",
    "    instance_type=\"Standard_F4s_v2\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint ch6-sdkv2-endpt-12102241150428 exists\n",
      "\u001b[32mUploading ManagedOnlineEndpoint (0.0 MBs): 100%|██████████| 940/940 [00:00<00:00, 31502.61it/s]\n",
      "\u001b[39m\n",
      "\n",
      "data_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7fd488896950>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(blue_deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "..Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "....Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "..Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "....Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "..."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Succeeded'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "while ml_client.online_deployments.get(name = \"blue\", endpoint_name = online_endpoint_name).provisioning_state == 'Updating':\n",
    "    print('Updating..will take about 10 minutes to deploy...')\n",
    "    time.sleep(15)\n",
    "    \n",
    "ml_client.online_deployments.get(name = \"blue\", endpoint_name = online_endpoint_name).provisioning_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7fd488897b20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blue deployment takes 100 traffic\n",
    "endpoint.traffic = {\"blue\": 100}\n",
    "ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating\n",
      "Updating\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Succeeded'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "while ml_client.online_endpoints.get(name=online_endpoint_name).provisioning_state == 'Updating':\n",
    "    print('Updating')\n",
    "    time.sleep(15)\n",
    "    \n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "endpoint.provisioning_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://ch6-sdkv2-endpt-12102241150428.eastus.inference.ml.azure.com/score', 'openapi_uri': 'https://ch6-sdkv2-endpt-12102241150428.eastus.inference.ml.azure.com/swagger.json', 'name': 'ch6-sdkv2-endpt-12102241150428', 'description': 'titanic online endpoint for mlflow model', 'tags': {'oneline endpoint': 'titanic'}, 'properties': {'azureml.onlineendpointid': '/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/chapter6-azureml-rg/providers/microsoft.machinelearningservices/workspaces/chapter6-azureml/onlineendpoints/ch6-sdkv2-endpt-12102241150428', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/providers/Microsoft.MachineLearningServices/locations/eastus/mfeOperationsStatus/oe:9e44248b-9077-4922-99ad-0c577c53684e:6b0c72f7-7c63-45b3-8456-25c058b85b93?api-version=2022-02-01-preview'}, 'id': '/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourceGroups/chapter6-azureml-rg/providers/Microsoft.MachineLearningServices/workspaces/chapter6-azureml/onlineEndpoints/ch6-sdkv2-endpt-12102241150428', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz2/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/chapter 6', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fd488897640>, 'auth_mode': 'key', 'location': 'eastus', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7fd4ab5d86a0>, 'traffic': {'blue': 100}, 'mirror_traffic': {}, 'kind': 'Managed'})\n",
      " \n",
      "{'blue': 100}\n",
      " \n",
      "uri: https://ch6-sdkv2-endpt-12102241150428.eastus.inference.ml.azure.com/score\n",
      " \n",
      "primary key: s88iivB6eDuW8yd9SMOZ7nceHpU93VEI\n"
     ]
    }
   ],
   "source": [
    "# Get the details for online endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "print(endpoint)\n",
    "print(' ')\n",
    "# existing traffic details\n",
    "print(endpoint.traffic)\n",
    "print(' ')\n",
    "# Get the scoring URI\n",
    "print('uri: ' + str(endpoint.scoring_uri))\n",
    "primary_key = ml_client.online_endpoints.get_keys(name = online_endpoint_name).primary_key\n",
    "print(' ')\n",
    "print('primary key: ' + str(primary_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>GroupSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embarked Loc Sex  Pclass   Age     Fare  GroupSize\n",
       "0        S   X   m       3  22.0   7.2500          2\n",
       "1        C   C   f       1  38.0  71.2833          2\n",
       "2        S   X   f       3  26.0   7.9250          1\n",
       "3        S   C   f       1  35.0  53.1000          2\n",
       "4        S   X   m       3  35.0   8.0500          1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./prepped_data/titanic_prepped.csv')\n",
    "columns_to_keep =  ['Embarked', 'Loc', 'Sex','Pclass', 'Age', 'Fare', 'GroupSize']\n",
    "X_raw           = df[columns_to_keep].head(5)\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"raw_data\": [{\"Embarked\":\"S\",\"Loc\":\"X\",\"Sex\":\"m\",\"Pclass\":3,\"Age\":22.0,\"Fare\":7.25,\"GroupSize\":2},{\"Embarked\":\"C\",\"Loc\":\"C\",\"Sex\":\"f\",\"Pclass\":1,\"Age\":38.0,\"Fare\":71.2833,\"GroupSize\":2},{\"Embarked\":\"S\",\"Loc\":\"X\",\"Sex\":\"f\",\"Pclass\":3,\"Age\":26.0,\"Fare\":7.925,\"GroupSize\":1},{\"Embarked\":\"S\",\"Loc\":\"C\",\"Sex\":\"f\",\"Pclass\":1,\"Age\":35.0,\"Fare\":53.1,\"GroupSize\":2},{\"Embarked\":\"S\",\"Loc\":\"X\",\"Sex\":\"m\",\"Pclass\":3,\"Age\":35.0,\"Fare\":8.05,\"GroupSize\":1}]}\n",
      "{'result': [0, 1, 0, 1, 0]}\n",
      "\n",
      "predictions\n",
      "[0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "url = endpoint.scoring_uri\n",
    "api_key = primary_key  # Replace this with the API key for the web service\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "import requests\n",
    "\n",
    "def make_prediction(df):\n",
    "    endpoint_url = url\n",
    "    body = df.to_json(orient='records') \n",
    "    body = '{\"raw_data\": ' + body + '}'\n",
    "    print(body)\n",
    "    r = requests.post(endpoint_url, headers=headers, data=body)\n",
    "    return (r.json())\n",
    "\n",
    "\n",
    "columns_to_keep =  ['Embarked', 'Loc', 'Sex','Pclass', 'Age', 'Fare', 'GroupSize']\n",
    "X_raw           = df[columns_to_keep]\n",
    "\n",
    "\n",
    "dftest = X_raw.head(5)\n",
    "\n",
    "results = make_prediction(dftest)\n",
    "\n",
    "print(results)\n",
    "val = results['result']\n",
    "print('')\n",
    "print('predictions')\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "job_env"
  },
  "kernelspec": {
   "display_name": "job_env",
   "language": "python",
   "name": "job_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
