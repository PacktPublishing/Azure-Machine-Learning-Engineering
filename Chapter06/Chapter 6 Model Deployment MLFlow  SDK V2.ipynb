{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy MLflow Model to online endpoint\n",
    "\n",
    "- Before running this notebook, run the **Chapter 6 Prep-Model Creation & Registration.ipynb** notebook to create and register a model for use\n",
    "\n",
    "- Models created with MLFlow do not require a scoring script nor an environment\n",
    "\n",
    "## In this notebook we will:\n",
    "\n",
    "- Connect to your workspace.\n",
    "- Create an online endpoint\n",
    "- Retrieve and register a model from the job ran in the previous notebook\n",
    "- Create a deployment\n",
    "- Make an API Call to the managed online endpoint\n",
    "\n",
    "You can use either the Python 3.10 - SDK V2 kernel, or your job_env kenel to run this notebook.\n",
    "\n",
    "**Kernel** > **Change Kernel** > **Python 3.10 - SDK V2**\n",
    "\n",
    "or if you already setup the virtual environment in Chapter 4:\n",
    "\n",
    "Select **Kernel** > **Change Kernel** > **job_env**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import azure.ai.ml\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "\n",
    "print(azure.ai.ml._version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "resource_group = \"<RESOURCE_GROUP>\"\n",
    "workspace = \"<AML_WORKSPACE_NAME>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Online Endpoint\n",
    "\n",
    "To create an online endpoint, we will leverage the class *ManagedOnlineEndpoint*.  To create the online endpoint we will provide the following configuration:\n",
    "\n",
    "- name of endpoint\n",
    "- description\n",
    "- auth_mode (set to key) or aml_token\n",
    "- tags - to provide information regarding the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "import datetime\n",
    "\n",
    "online_endpoint_name = \"chp6-mlflow-endpt-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"titanic online endpoint for mlflow model\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"mlflow\": \"true\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create endpoint\n",
    "\n",
    "Using the MLClient created earlier, we will now create the Endpoint in the workspace. This command will start the endpoint creation and return a confirmation response while the endpoint creation continues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7f02dd261d20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create deployment\n",
    "A deployment is a set of resouces used for hosting the inferecing model using the *ManagedOnlineDeployment* class.  \n",
    "Using the *ManagedOnlineDeployment* class, a developer can configure the following components\n",
    "\n",
    "- name: name of the deployment\n",
    "- endpoint_name: name of the endpoint to create the deployment under\n",
    "- model: the model to use for the deployment\n",
    "- instance_type: the VM side to use for deployment\n",
    "- instance_count: the number of instances to use for the deployment\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Model from Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = ml_client.models.get(name=\"chapter6_titanic_model\", version=\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the deployment\n",
    "\n",
    "- retrieve the experiment id for this run, and the run id to retrieve the model from the registered model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Succeeded\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while ml_client.online_endpoints.get(name=online_endpoint_name).provisioning_state == 'Creating':\n",
    "    print('Creating')\n",
    "    time.sleep(15)\n",
    "\n",
    "print(ml_client.online_endpoints.get(name=online_endpoint_name).provisioning_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=run_model,\n",
    "    instance_type=\"Standard_F4s_v2\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chp6-mlflow-endpt-12102106054771\n"
     ]
    }
   ],
   "source": [
    "## Create deployment\n",
    "print(online_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint chp6-mlflow-endpt-12102106054771 exists\n",
      "data_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7f02dd263c40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(blue_deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Updating..will take about 10 minutes to deploy...\n",
      "..Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "....Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "..Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "..Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      "...Updating..will take about 10 minutes to deploy...\n",
      ".."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Succeeded'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "while ml_client.online_deployments.get(name = \"blue\", endpoint_name = online_endpoint_name).provisioning_state == 'Updating':\n",
    "    print('Updating..will take about 10 minutes to deploy...')\n",
    "    time.sleep(15)\n",
    "    \n",
    "ml_client.online_deployments.get(name = \"blue\", endpoint_name = online_endpoint_name).provisioning_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Instance status:\\nSystemSetup: Succeeded\\nUserContainerImagePull: Succeeded\\nModelDownload: Succeeded\\nUserContainerStart: Succeeded\\n\\nContainer events:\\nKind: Pod, Name: Started, Type: Normal, Time: 2022-12-10T21:19:14.635778Z, Message: Started container inference-server\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-12-10T21:19:30.648767Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-12-10T21:19:32.372952Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-12-10T21:19:40.648584Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-12-10T21:19:42.373102Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-12-10T21:19:50.648573Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-12-10T21:19:52.372937Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-12-10T21:20:00.648605Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-12-10T21:20:02.373006Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-12-10T21:20:10.648849Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-12-10T21:20:12.372989Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-12-10T21:20:20.648594Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-12-10T21:20:22.372749Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-12-10T21:20:31.930316Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-12-10T21:20:32.372888Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-12-10T21:20:40.648453Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-12-10T21:20:42.372932Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-12-10T21:20:50.648418Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-12-10T21:20:52.372773Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ContainerReady, Type: Normal, Time: 2022-12-10T21:21:00.965104159Z, Message: Container is ready\\n\\nContainer logs:\\n2022-12-10T21:20:56,206618287+00:00 | gunicorn/run | ###############################################\\n2022-12-10T21:20:56,208230483+00:00 | gunicorn/run | \\n2022-12-10T21:20:56,209923579+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\\n\\nAzure ML Inferencing HTTP server v0.7.7\\n\\n\\nServer Settings\\n---------------\\nEntry Script Name: /var/mlflow_resources/mlflow_score_script.py\\nModel Directory: /var/azureml-app/azureml-models/chapter6_titanic_model/1\\nWorker Count: 1\\nWorker Timeout (seconds): 300\\nServer Port: 31311\\nApplication Insights Enabled: false\\nApplication Insights Key: None\\nInferencing HTTP server version: azmlinfsrv/0.7.7\\nCORS for the specified origins: None\\n\\n\\nServer Routes\\n---------------\\nLiveness Probe: GET   127.0.0.1:31311/\\nScore:          POST  127.0.0.1:31311/score\\n\\nStarting gunicorn 20.1.0\\nListening at: http://0.0.0.0:31311 (8)\\nUsing worker: sync\\nBooting worker with pid: 684\\nInitializing logger\\nStarting up app insights client\\n2022-12-10 21:20:56,667 | root | INFO | Starting up app insights client\\nlogging socket not found. logging not available.\\nlogging socket not found. logging not available.\\nStarting up app insight hooks\\n2022-12-10 21:20:56,668 | root | INFO | Starting up app insight hooks\\nFound user script at /var/mlflow_resources/mlflow_score_script.py\\n2022-12-10 21:20:57,742 | root | INFO | Found user script at /var/mlflow_resources/mlflow_score_script.py\\nrun() is decorated with @input_schema. Server will invoke it with the following arguments: input_data.\\n2022-12-10 21:20:57,743 | root | INFO | run() is decorated with @input_schema. Server will invoke it with the following arguments: input_data.\\nInvoking user's init function\\n2022-12-10 21:20:57,743 | root | INFO | Invoking user's init function\\nUsers's init has completed successfully\\n2022-12-10 21:20:57,743 | root | INFO | Users's init has completed successfully\\nSwaggers are prepared for versions [3] and skipped for versions [2].\\n2022-12-10 21:20:57,743 | root | INFO | Swaggers are prepared for versions [3] and skipped for versions [2].\\nScoring timeout setting is not found. Use default timeout: 3600000 ms\\n2022-12-10 21:20:57,743 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\nAML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\\n2022-12-10 21:20:57,744 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\\n\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get status of online deployment\n",
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"blue\", endpoint_name=online_endpoint_name, lines=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7f02dd2d10f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blue deployment takes 100 traffic\n",
    "endpoint.traffic = {\"blue\": 100}\n",
    "ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking provisioning state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating\n",
      "Updating\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Succeeded'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "while ml_client.online_endpoints.get(name=online_endpoint_name).provisioning_state == 'Updating':\n",
    "    print('Updating')\n",
    "    time.sleep(15)\n",
    "    \n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "endpoint.provisioning_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Endpoint details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://chp6-mlflow-endpt-12102106054771.eastus.inference.ml.azure.com/score', 'openapi_uri': 'https://chp6-mlflow-endpt-12102106054771.eastus.inference.ml.azure.com/swagger.json', 'name': 'chp6-mlflow-endpt-12102106054771', 'description': 'titanic online endpoint for mlflow model', 'tags': {'mlflow': 'true'}, 'properties': {'azureml.onlineendpointid': '/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/chapter6-azureml-rg/providers/microsoft.machinelearningservices/workspaces/chapter6-azureml/onlineendpoints/chp6-mlflow-endpt-12102106054771', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/providers/Microsoft.MachineLearningServices/locations/eastus/mfeOperationsStatus/oe:9e44248b-9077-4922-99ad-0c577c53684e:e7497d00-9689-453e-935f-f45adc840b94?api-version=2022-02-01-preview'}, 'id': '/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourceGroups/chapter6-azureml-rg/providers/Microsoft.MachineLearningServices/workspaces/chapter6-azureml/onlineEndpoints/chp6-mlflow-endpt-12102106054771', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz2/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/chapter 6', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f02dd2d1f00>, 'auth_mode': 'key', 'location': 'eastus', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7f02df3daaa0>, 'traffic': {'blue': 100}, 'mirror_traffic': {}, 'kind': 'Managed'})\n",
      " \n",
      "{'blue': 100}\n",
      " \n",
      "uri: https://chp6-mlflow-endpt-12102106054771.eastus.inference.ml.azure.com/score\n",
      " \n",
      "primary key: VIhmf5SVCNtAyfAGzlGhBTDqStQfAd1c\n"
     ]
    }
   ],
   "source": [
    "# Get the details for online endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "print(endpoint)\n",
    "print(' ')\n",
    "# existing traffic details\n",
    "print(endpoint.traffic)\n",
    "print(' ')\n",
    "# Get the scoring URI\n",
    "print('uri: ' + str(endpoint.scoring_uri))\n",
    "primary_key = ml_client.online_endpoints.get_keys(name = online_endpoint_name).primary_key\n",
    "print(' ')\n",
    "print('primary key: ' + str(primary_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leverage the registered ml table from Chapter 4 to get some data to send to the rest endpoint.\n",
    "\n",
    "- Previously in Chapter 4, we registered the MLTable: titanic_prepped_mltable_x2, we will retrieve it, if we don't have it registered, we can leverage the data directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml://subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/chapter6-azureml-rg/workspaces/chapter6-azureml/datastores/workspaceblobstore/paths/LocalUpload/b3e9d2d76d36b52fc88b17546f0f0460/titanic_prepped_mltable/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized authentication type: None\n",
      "Unrecognized authentication type: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved data frame from registered mltable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>GroupSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embarked Loc Sex Pclass   Age     Fare GroupSize\n",
       "0        S   X   m      3  22.0     7.25         2\n",
       "1        C   C   f      1  38.0  71.2833         2\n",
       "2        S   X   f      3  26.0    7.925         1\n",
       "3        S   C   f      1  35.0     53.1         2\n",
       "4        S   X   m      3  35.0     8.05         1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mltable\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    registered_v1_data_asset = ml_client.data.get(name='titanic_prepped_mltable_x2', version='1')\n",
    "    print(registered_v1_data_asset.path)\n",
    "\n",
    "    tbl = mltable.load(uri=registered_v1_data_asset.path)\n",
    "    df = tbl.to_pandas_dataframe()\n",
    "    print('retrieved data frame from registered mltable')\n",
    "except:\n",
    "   \n",
    "    df = pd.read_csv('./prepped_data/titanic_prepped.csv')\n",
    "    \n",
    "columns_to_keep =  ['Embarked', 'Loc', 'Sex','Pclass', 'Age', 'Fare', 'GroupSize']\n",
    "X_raw           = df[columns_to_keep].head(5)\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>GroupSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>m</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>S</td>\n",
       "      <td>B</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>21.5</td>\n",
       "      <td>23.45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Q</td>\n",
       "      <td>X</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Embarked Loc Sex Pclass   Age     Fare GroupSize\n",
       "0          S   X   m      3  22.0     7.25         2\n",
       "1          C   C   f      1  38.0  71.2833         2\n",
       "2          S   X   f      3  26.0    7.925         1\n",
       "3          S   C   f      1  35.0     53.1         2\n",
       "4          S   X   m      3  35.0     8.05         1\n",
       "..       ...  ..  ..    ...   ...      ...       ...\n",
       "886        S   X   m      2  27.0     13.0         1\n",
       "887        S   B   f      1  19.0     30.0         1\n",
       "888        S   X   f      3  21.5    23.45         4\n",
       "889        C   C   m      1  26.0     30.0         1\n",
       "890        Q   X   m      3  32.0     7.75         1\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep =  ['Embarked', 'Loc', 'Sex','Pclass', 'Age', 'Fare', 'GroupSize']\n",
    "X_raw           = df[columns_to_keep]\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"input_data\": {\"columns\": [\"Embarked\", \"Loc\", \"Sex\", \"Pclass\", \"Age\", \"Fare\", \"GroupSize\"], \"data\": [{\"Embarked\": \"S\", \"Loc\": \"X\", \"Sex\": \"m\", \"Pclass\": \"3\", \"Age\": \"22.0\", \"Fare\": \"7.25\", \"GroupSize\": \"2\"}, {\"Embarked\": \"C\", \"Loc\": \"C\", \"Sex\": \"f\", \"Pclass\": \"1\", \"Age\": \"38.0\", \"Fare\": \"71.2833\", \"GroupSize\": \"2\"}]}}\n",
      "\n",
      "predictions\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "url = endpoint.scoring_uri\n",
    "api_key = primary_key  # Replace this with the API key for the web service\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'blue' }\n",
    "import requests\n",
    "\n",
    "def make_prediction(df):\n",
    "    strjson = str(df.to_json(orient='records'))\n",
    "    endpoint_url = url\n",
    "\n",
    "    request_data =  {\n",
    "              \"input_data\": {\n",
    "                \"columns\": [\n",
    "                  \"Embarked\",\n",
    "                  \"Loc\",\n",
    "                  \"Sex\",\n",
    "                  \"Pclass\",\n",
    "                  \"Age\",\n",
    "                  \"Fare\",\n",
    "                  \"GroupSize\"\n",
    "                ],\n",
    "                \"data\": []\n",
    "              }\n",
    "            }\n",
    "\n",
    "    request_df = X_raw.head(2)\n",
    "    request_data['input_data']['data'] = json.loads(request_df.to_json(orient='records'))\n",
    "    parsed = json.dumps(request_data)\n",
    "    print(parsed)\n",
    "    r = requests.post(endpoint_url, headers=headers, data=parsed)\n",
    "    return (r.json())\n",
    "\n",
    "results = make_prediction(X_raw.head(2))\n",
    "print('')\n",
    "print('predictions')\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "job_env"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK V2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
